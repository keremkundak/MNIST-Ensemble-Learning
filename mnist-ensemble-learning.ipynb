{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/keremkundak/mnist-ensemble-learning?scriptVersionId=217230706\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:04:52.898491Z","iopub.execute_input":"2025-01-11T22:04:52.89884Z","iopub.status.idle":"2025-01-11T22:04:53.287413Z","shell.execute_reply.started":"2025-01-11T22:04:52.898813Z","shell.execute_reply":"2025-01-11T22:04:53.28617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Import libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:04:53.288908Z","iopub.execute_input":"2025-01-11T22:04:53.289424Z","iopub.status.idle":"2025-01-11T22:04:54.507129Z","shell.execute_reply.started":"2025-01-11T22:04:53.289357Z","shell.execute_reply":"2025-01-11T22:04:54.50597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load MNIST dataset\nmnist = fetch_openml('mnist_784', version=1, as_frame=False, parser='auto')\nX, y = mnist.data, mnist.target.astype(np.uint8)\n\n# Split the data\nX_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=10000, random_state=42)\nX_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, train_size=50000, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:04:54.509086Z","iopub.execute_input":"2025-01-11T22:04:54.509635Z","iopub.status.idle":"2025-01-11T22:05:08.267326Z","shell.execute_reply.started":"2025-01-11T22:04:54.5096Z","shell.execute_reply":"2025-01-11T22:05:08.266344Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Scale the data\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\nprint(f\"Training set: {X_train_scaled.shape}\")\nprint(f\"Validation set: {X_val_scaled.shape}\")\nprint(f\"Test set: {X_test_scaled.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:05:08.2688Z","iopub.execute_input":"2025-01-11T22:05:08.269157Z","iopub.status.idle":"2025-01-11T22:05:09.142994Z","shell.execute_reply.started":"2025-01-11T22:05:08.269117Z","shell.execute_reply":"2025-01-11T22:05:09.141757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize classifiers with carefully tuned hyperparameters\nclassifiers = {\n    'Random Forest': RandomForestClassifier(\n        n_estimators=200, \n        max_depth=15, \n        min_samples_split=5, \n        random_state=42\n    ),\n    'Decision Tree': DecisionTreeClassifier(\n        max_depth=10,\n        min_samples_split=5,\n        min_samples_leaf=2,\n        random_state=42\n    ),\n    'Logistic Regression': LogisticRegression(\n        multi_class='multinomial', \n        solver='lbfgs', \n        C=0.1, \n        max_iter=1000, \n        random_state=42\n    ),\n    'MLP': MLPClassifier(\n        hidden_layer_sizes=(100, 50),\n        activation='relu',\n        solver='adam',\n        alpha=0.0001,\n        learning_rate='adaptive',\n        max_iter=500,\n        random_state=42\n    ),\n    'Naive Bayes': GaussianNB(),\n    'KNN': KNeighborsClassifier(\n        n_neighbors=5,\n        weights='uniform',\n        algorithm='auto',\n        p=2\n    )\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:05:09.14406Z","iopub.execute_input":"2025-01-11T22:05:09.144457Z","iopub.status.idle":"2025-01-11T22:05:09.150731Z","shell.execute_reply.started":"2025-01-11T22:05:09.144426Z","shell.execute_reply":"2025-01-11T22:05:09.149481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dictionary to store classifier performances\nclassifier_performances = {}\n\nprint(\"\\nIndividual Classifier Performances:\")\n\n# Train and evaluate each classifier on validation set\nfor name, clf in classifiers.items():\n    # Train the classifier\n    clf.fit(X_train_scaled, y_train)\n    \n    # Predict on validation set\n    val_pred = clf.predict(X_val_scaled)\n    val_accuracy = accuracy_score(y_val, val_pred)\n    \n    # Store performance\n    classifier_performances[name] = val_accuracy\n    \n    print(f\"{name} Validation Accuracy: {val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:05:09.151879Z","iopub.execute_input":"2025-01-11T22:05:09.152202Z","iopub.status.idle":"2025-01-11T22:08:31.981859Z","shell.execute_reply.started":"2025-01-11T22:05:09.152171Z","shell.execute_reply":"2025-01-11T22:08:31.980797Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create soft voting ensemble\nsoft_voting_clf = VotingClassifier(\n    estimators=[(name, clf) for name, clf in classifiers.items()],\n    voting='soft')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:08:31.982792Z","iopub.execute_input":"2025-01-11T22:08:31.983088Z","iopub.status.idle":"2025-01-11T22:08:31.987491Z","shell.execute_reply.started":"2025-01-11T22:08:31.983065Z","shell.execute_reply":"2025-01-11T22:08:31.986444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train and evaluate soft voting ensemble\nsoft_voting_clf.fit(X_train_scaled, y_train)\nsoft_val_pred = soft_voting_clf.predict(X_val_scaled)\nsoft_val_accuracy = accuracy_score(y_val, soft_val_pred)\nclassifier_performances['Soft Voting Ensemble'] = soft_val_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:08:31.990285Z","iopub.execute_input":"2025-01-11T22:08:31.990706Z","iopub.status.idle":"2025-01-11T22:11:47.943758Z","shell.execute_reply.started":"2025-01-11T22:08:31.990676Z","shell.execute_reply":"2025-01-11T22:11:47.942732Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create hard voting ensemble\nhard_voting_clf = VotingClassifier(\n    estimators=[(name, clf) for name, clf in classifiers.items()],\n    voting='hard')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:11:47.94503Z","iopub.execute_input":"2025-01-11T22:11:47.945295Z","iopub.status.idle":"2025-01-11T22:11:47.949484Z","shell.execute_reply.started":"2025-01-11T22:11:47.945271Z","shell.execute_reply":"2025-01-11T22:11:47.948625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train and evaluate hard voting ensemble on validation set\nhard_voting_clf.fit(X_train_scaled, y_train)\nhard_val_pred = hard_voting_clf.predict(X_val_scaled)\nhard_val_accuracy = accuracy_score(y_val, hard_val_pred)\nclassifier_performances['Hard Voting Ensemble'] = hard_val_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:11:47.950652Z","iopub.execute_input":"2025-01-11T22:11:47.950957Z","iopub.status.idle":"2025-01-11T22:15:03.390797Z","shell.execute_reply.started":"2025-01-11T22:11:47.950932Z","shell.execute_reply":"2025-01-11T22:15:03.38959Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Soft Voting Ensemble Validation Accuracy: {soft_val_accuracy:.4f}\")\nprint(f\"Hard Voting Ensemble Validation Accuracy: {hard_val_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:15:03.391919Z","iopub.execute_input":"2025-01-11T22:15:03.392308Z","iopub.status.idle":"2025-01-11T22:15:03.398142Z","shell.execute_reply.started":"2025-01-11T22:15:03.39227Z","shell.execute_reply":"2025-01-11T22:15:03.397193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Sort classifiers by their validation accuracy\nsorted_performances = sorted(\n    classifier_performances.items(), \n    key=lambda x: x[1], \n    reverse=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:15:03.399207Z","iopub.execute_input":"2025-01-11T22:15:03.399556Z","iopub.status.idle":"2025-01-11T22:15:03.420517Z","shell.execute_reply.started":"2025-01-11T22:15:03.39953Z","shell.execute_reply":"2025-01-11T22:15:03.419343Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a bar plot of classifier performances\nplt.figure(figsize=(10, 6))\nnames, accuracies = zip(*sorted_performances)\nplt.bar(names, accuracies)\nplt.title('Classifier Performance on Validation Set')\nplt.xlabel('Classifiers')\nplt.ylabel('Validation Accuracy')\nplt.ylim(0.8, 1.0)\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:15:03.421347Z","iopub.execute_input":"2025-01-11T22:15:03.421672Z","iopub.status.idle":"2025-01-11T22:15:03.729711Z","shell.execute_reply.started":"2025-01-11T22:15:03.421646Z","shell.execute_reply":"2025-01-11T22:15:03.728346Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>The ensemble model could not outperform the other individual models. Let's try again by removing the decision tree, logistic regression and naive bayes classifiers that have low accuracy rates.</h3>\n","metadata":{}},{"cell_type":"code","source":"# Updated classifiers dictionary\nupdated_classifiers = {\n    'Random Forest': RandomForestClassifier(\n        n_estimators=200, \n        max_depth=15, \n        min_samples_split=5, \n        random_state=42\n    ),\n    'KNN': KNeighborsClassifier(\n        n_neighbors=5,\n        weights='uniform',\n        algorithm='auto',\n        p=2\n    ),\n    'MLP': MLPClassifier(\n        hidden_layer_sizes=(100, 50),  \n        activation='relu',\n        solver='adam',\n        alpha=0.0001,\n        learning_rate='adaptive',\n        max_iter=500,\n        random_state=42\n    )\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:15:03.730726Z","iopub.execute_input":"2025-01-11T22:15:03.731058Z","iopub.status.idle":"2025-01-11T22:15:03.736438Z","shell.execute_reply.started":"2025-01-11T22:15:03.731031Z","shell.execute_reply":"2025-01-11T22:15:03.73533Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Update soft voting Ensemble\nsoft_voting_clf = VotingClassifier(\n    estimators=[(name, clf) for name, clf in updated_classifiers.items()],\n    voting='soft'\n)\n\n# Update hard voting Ensemble\nhard_voting_clf = VotingClassifier(\n    estimators=[(name, clf) for name, clf in updated_classifiers.items()],\n    voting='hard'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:15:03.737506Z","iopub.execute_input":"2025-01-11T22:15:03.737858Z","iopub.status.idle":"2025-01-11T22:15:03.757637Z","shell.execute_reply.started":"2025-01-11T22:15:03.737822Z","shell.execute_reply":"2025-01-11T22:15:03.756481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train and evaluate updated soft voting ensemble on validation set\nsoft_voting_clf.fit(X_train_scaled, y_train)\nsoft_val_pred = soft_voting_clf.predict(X_val_scaled)\nsoft_val_accuracy = accuracy_score(y_val, soft_val_pred)\nclassifier_performances['Updated Soft Voting Ensemble'] = soft_val_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:15:03.758828Z","iopub.execute_input":"2025-01-11T22:15:03.759231Z","iopub.status.idle":"2025-01-11T22:17:17.039144Z","shell.execute_reply.started":"2025-01-11T22:15:03.759194Z","shell.execute_reply":"2025-01-11T22:17:17.038037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train and evaluate updated hard voting ensemble on validation set\nhard_voting_clf.fit(X_train_scaled, y_train)\nhard_val_pred = hard_voting_clf.predict(X_val_scaled)\nhard_val_accuracy = accuracy_score(y_val, hard_val_pred)\nclassifier_performances['Updated Hard Voting Ensemble'] = hard_val_accuracy\n(\"\\nEnsemble Performance:\")\nprint(f\"Updated Soft Voting Ensemble Validation Accuracy: {soft_val_accuracy:.4f}\")\nprint(f\"Updated Hard Voting Ensemble Validation Accuracy: {hard_val_accuracy:.4f}\")\n# Sort classifiers by their validation accuracy\nsorted_performances = sorted(\n    classifier_performances.items(), \n    key=lambda x: x[1], \n    reverse=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:17:17.040001Z","iopub.execute_input":"2025-01-11T22:17:17.040344Z","iopub.status.idle":"2025-01-11T22:19:30.296978Z","shell.execute_reply.started":"2025-01-11T22:17:17.040312Z","shell.execute_reply":"2025-01-11T22:19:30.295611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create a bar plot of classifier performances\nplt.figure(figsize=(10, 6))\nnames, accuracies = zip(*sorted_performances)\nplt.bar(names, accuracies)\nplt.title('Classifier Performance on Validation Set')\nplt.xlabel('Classifiers')\nplt.ylabel('Validation Accuracy')\nplt.ylim(0.8, 1.0)\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:19:30.297875Z","iopub.execute_input":"2025-01-11T22:19:30.298249Z","iopub.status.idle":"2025-01-11T22:19:30.585114Z","shell.execute_reply.started":"2025-01-11T22:19:30.298205Z","shell.execute_reply":"2025-01-11T22:19:30.583865Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>Now, we have an ensemble model that outperforms all the individual classifiers.</h3>","metadata":{}},{"cell_type":"code","source":"# Evaluate individual classifiers on test set\nprint(\"\\nTest Set Performance:\")\nfor name, clf in classifiers.items():\n    test_pred = clf.predict(X_test_scaled)\n    test_accuracy = accuracy_score(y_test, test_pred)\n    print(f\"{name} Test Accuracy: {test_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:19:30.586193Z","iopub.execute_input":"2025-01-11T22:19:30.586537Z","iopub.status.idle":"2025-01-11T22:19:45.194268Z","shell.execute_reply.started":"2025-01-11T22:19:30.586507Z","shell.execute_reply":"2025-01-11T22:19:45.193181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate soft voting ensemble on test set\nsoft_test_pred = soft_voting_clf.predict(X_test_scaled)\nsoft_test_accuracy = accuracy_score(y_test, soft_test_pred)\nprint(f\"Soft Voting Ensemble Test Accuracy: {soft_test_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-11T22:19:45.195412Z","iopub.execute_input":"2025-01-11T22:19:45.195807Z","iopub.status.idle":"2025-01-11T22:19:58.092425Z","shell.execute_reply.started":"2025-01-11T22:19:45.195771Z","shell.execute_reply":"2025-01-11T22:19:58.090628Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>Soft voting ensemble reduced the error rate of the best indivudual model from about 2.79% to 2.6%, which means about 6.81% less errors.</h3>","metadata":{}}]}